{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# HTTP-Header f√ºr die Anfrage\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "    \"Referer\": \"https://www.tagesschau.de/archiv\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\"\n",
    "}\n",
    "\n",
    "# Funktion zum Crawlen der Headlines eines bestimmten Tages\n",
    "def crawl_archiv_tag(datum):\n",
    "    datum_str = datum.strftime(\"%Y-%m-%d\")\n",
    "    url = f\"https://www.tagesschau.de/archiv?datum={datum_str}\"\n",
    "    print(f\"üì• Lade: {url}\")\n",
    "\n",
    "    res = requests.get(url, headers=headers)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"‚ö†Ô∏è Fehler {res.status_code} f√ºr {datum_str}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    artikel = []\n",
    "\n",
    "    # Selektor f√ºr die Artikel anpassen\n",
    "    for teaser in soup.select(\"div.teaser-right\"):\n",
    "        titel_tag = teaser.select_one(\"span.teaser-right__headline\")\n",
    "        titel = titel_tag.get_text(strip=True) if titel_tag else \"Kein Titel\"\n",
    "\n",
    "        labeltop_tag = teaser.select_one(\"span.teaser-right__labeltopline\")\n",
    "        labeltop = labeltop_tag.get_text(strip=True) if labeltop_tag else \"Kein Label\"\n",
    "\n",
    "        shortext_tag = teaser.select_one(\"p.teaser-right__shorttext\")\n",
    "        shortext = shortext_tag.get_text(strip=True) if shortext_tag else \"Kein Shorttext\"\n",
    "\n",
    "        autor_tag = shortext_tag.select_one(\"em\") if shortext_tag else None\n",
    "        autor = autor_tag.get_text(strip=True) if autor_tag else \"Kein Autor\"\n",
    "\n",
    "        link_tag = teaser.select_one(\"a.teaser-right__link\")\n",
    "        link = link_tag[\"href\"] if link_tag else \"Kein Link\"\n",
    "        if not link.startswith(\"http\"):\n",
    "            link = \"https://www.tagesschau.de\" + link\n",
    "\n",
    "        # Datum aus dem HTML extrahieren und in ISO-Format umwandeln\n",
    "        datum_tag = teaser.select_one(\"div.teaser-right__date\")\n",
    "        raw_datum = datum_tag.get_text(strip=True) if datum_tag else \"Kein Datum\"\n",
    "        try:\n",
    "            # Konvertiere das Datum in ISO-Format\n",
    "            datum_iso = datetime.strptime(raw_datum, \"%d.%m.%Y ‚Ä¢ %H:%M Uhr\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            datum_iso = \"Unbekannt\"\n",
    "\n",
    "        # Ressort aus der URL extrahieren\n",
    "        ressort = link.split(\"/\")[3] if link != \"Kein Link\" else \"Unbekannt\"\n",
    "\n",
    "        artikel.append({\n",
    "            \"datum\": datum_iso,\n",
    "            \"titel\": titel,\n",
    "            \"ressort\": ressort,\n",
    "            \"labeltop\": labeltop,\n",
    "            \"shorttext\": shortext,\n",
    "            \"autor\": autor,\n",
    "            \"link\": link\n",
    "        })\n",
    "\n",
    "    return artikel\n",
    "\n",
    "# Funktion zum Crawlen eines Zeitbereichs\n",
    "def crawl_timeframe(start_date, end_date):\n",
    "    alle = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        artikel = crawl_archiv_tag(current_date)\n",
    "        alle.extend(artikel)\n",
    "        current_date += timedelta(days=1)\n",
    "    return alle\n",
    "\n",
    "# Hauptlauf\n",
    "# Zeitbereich angeben (z. B. vom 1. Mai 2025 bis 8. Mai 2025)\n",
    "start_date = datetime(2025, 5, 1)\n",
    "end_date = datetime(2025, 5, 8)\n",
    "\n",
    "artikel = crawl_timeframe(start_date, end_date)\n",
    "df = pd.DataFrame(artikel)\n",
    "df.to_csv(\"tagesschau_headlines.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ {len(df)} Artikel gespeichert in tagesschau_headlines.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
